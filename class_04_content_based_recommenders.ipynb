{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "exciting-specific",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import Markdown, display, HTML\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import KFold\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "from evaluation_and_testing.testing import evaluate_train_test_split_explicit\n",
    "from evaluation_and_testing.testing import evaluate_leave_one_out_explicit\n",
    "from evaluation_and_testing.testing import evaluate_train_test_split_implicit\n",
    "from evaluation_and_testing.testing import evaluate_leave_one_out_implicit\n",
    "\n",
    "from recommenders.recommender import Recommender\n",
    "\n",
    "# Fix the dying kernel problem (only a problem in some installations - you can remove it, if it works without it)\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK'] = 'True'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "administrative-charleston",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "architectural-andrews",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_id</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Sabrina (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Tom and Huck (1995)</td>\n",
       "      <td>Adventure|Children</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Sudden Death (1995)</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>Action|Adventure|Thriller</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   item_id                               title  \\\n",
       "0        1                    Toy Story (1995)   \n",
       "1        2                      Jumanji (1995)   \n",
       "2        3             Grumpier Old Men (1995)   \n",
       "3        4            Waiting to Exhale (1995)   \n",
       "4        5  Father of the Bride Part II (1995)   \n",
       "5        6                         Heat (1995)   \n",
       "6        7                      Sabrina (1995)   \n",
       "7        8                 Tom and Huck (1995)   \n",
       "8        9                 Sudden Death (1995)   \n",
       "9       10                    GoldenEye (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                   Adventure|Children|Fantasy  \n",
       "2                               Comedy|Romance  \n",
       "3                         Comedy|Drama|Romance  \n",
       "4                                       Comedy  \n",
       "5                        Action|Crime|Thriller  \n",
       "6                               Comedy|Romance  \n",
       "7                           Adventure|Children  \n",
       "8                                       Action  \n",
       "9                    Action|Adventure|Thriller  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of left interactions: 9692\n"
     ]
    }
   ],
   "source": [
    "ml_ratings_df = pd.read_csv(os.path.join(\"data\", \"movielens_small\", \"ratings.csv\")).rename(columns={'userId': 'user_id', 'movieId': 'item_id'})\n",
    "ml_movies_df = pd.read_csv(os.path.join(\"data\", \"movielens_small\", \"movies.csv\")).rename(columns={'movieId': 'item_id'})\n",
    "ml_df = pd.merge(ml_ratings_df, ml_movies_df, on='item_id')\n",
    "\n",
    "display(ml_movies_df.head(10))\n",
    "\n",
    "# Filter the data to reduce the number of movies\n",
    "seed = 6789\n",
    "rng = np.random.RandomState(seed=seed)\n",
    "left_ids = rng.choice(ml_movies_df['item_id'], size=1000, replace=False)\n",
    "\n",
    "ml_ratings_df = ml_ratings_df.loc[ml_ratings_df['item_id'].isin(left_ids)]\n",
    "ml_movies_df = ml_movies_df.loc[ml_movies_df['item_id'].isin(left_ids)]\n",
    "ml_df = ml_df.loc[ml_df['item_id'].isin(left_ids)]\n",
    "\n",
    "print(\"Number of left interactions: {}\".format(len(ml_ratings_df)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-grill",
   "metadata": {},
   "source": [
    "# Baseline recommenders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlled-phoenix",
   "metadata": {},
   "source": [
    "**Task 1.** Implement the MostPopularRecommender (check the slides for class 1), evaluate it with leave-one-out procedure for implicit feedback, print HR@1, HR@3, HR@5, HR@10, NDCG@1, NDCG@3, NDCG@5, NDCG@10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "sixth-basketball",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 56>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m most_popular_recommender\u001b[38;5;241m.\u001b[39mfit(ml_ratings_df, \u001b[38;5;28;01mNone\u001b[39;00m, ml_movies_df)\n\u001b[0;32m     54\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m most_popular_recommender\u001b[38;5;241m.\u001b[39mrecommend(pd\u001b[38;5;241m.\u001b[39mDataFrame([[\u001b[38;5;241m1\u001b[39m], [\u001b[38;5;241m2\u001b[39m], [\u001b[38;5;241m6\u001b[39m]], columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m]), ml_movies_df, \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmerge\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrecommendations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mml_movies_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mitem_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mleft\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommendations\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m display(HTML(recommendations\u001b[38;5;241m.\u001b[39mto_html()))\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\reshape\\merge.py:107\u001b[0m, in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     91\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    105\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m    106\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m--> 107\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_MergeOperation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    109\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    110\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhow\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    111\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    112\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    113\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_on\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_on\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    114\u001b[0m \u001b[43m        \u001b[49m\u001b[43mleft_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mleft_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    115\u001b[0m \u001b[43m        \u001b[49m\u001b[43mright_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mright_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    116\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[43m        \u001b[49m\u001b[43msuffixes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msuffixes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    118\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    119\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindicator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindicator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    120\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    121\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    122\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\reshape\\merge.py:704\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    696\u001b[0m (\n\u001b[0;32m    697\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[0;32m    698\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[0;32m    699\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m    700\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[0;32m    702\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[0;32m    703\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m--> 704\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_coerce_merge_keys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    706\u001b[0m \u001b[38;5;66;03m# If argument passed to validate,\u001b[39;00m\n\u001b[0;32m    707\u001b[0m \u001b[38;5;66;03m# check if columns specified as unique\u001b[39;00m\n\u001b[0;32m    708\u001b[0m \u001b[38;5;66;03m# are in fact unique.\u001b[39;00m\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validate \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python310\\site-packages\\pandas\\core\\reshape\\merge.py:1257\u001b[0m, in \u001b[0;36m_MergeOperation._maybe_coerce_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1251\u001b[0m     \u001b[38;5;66;03m# unless we are merging non-string-like with string-like\u001b[39;00m\n\u001b[0;32m   1252\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m (\n\u001b[0;32m   1253\u001b[0m         inferred_left \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_right \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1254\u001b[0m     ) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   1255\u001b[0m         inferred_right \u001b[38;5;129;01min\u001b[39;00m string_types \u001b[38;5;129;01mand\u001b[39;00m inferred_left \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m string_types\n\u001b[0;32m   1256\u001b[0m     ):\n\u001b[1;32m-> 1257\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1259\u001b[0m \u001b[38;5;66;03m# datetimelikes must match exactly\u001b[39;00m\n\u001b[0;32m   1260\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m needs_i8_conversion(lk\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m needs_i8_conversion(rk\u001b[38;5;241m.\u001b[39mdtype):\n",
      "\u001b[1;31mValueError\u001b[0m: You are trying to merge on object and int64 columns. If you wish to proceed you should use pd.concat"
     ]
    }
   ],
   "source": [
    "class MostPopularRecommender(Recommender):\n",
    "    \"\"\"\n",
    "    Base recommender class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.most_popular_item = None\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        # Write your code here\n",
    "        offers_count = interactions_df.loc[:, ['item_id', 'user_id']].groupby('item_id').count()\n",
    "        offers_count = offers_count.sort_values('user_id', ascending=False)\n",
    "        self.most_popular_items = offers_count.index[:100]\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        for ix, user in users_df.iterrows():\n",
    "            user_recommendations = pd.DataFrame({'user_id': [user['user_id']],\n",
    "                                                 'item_id': [self.most_popular_item],\n",
    "                                                 'score': [1.0]})\n",
    "\n",
    "            recommendations = pd.concat([recommendations, user_recommendations])\n",
    "\n",
    "        return recommendations\n",
    "    \n",
    "# Quick test of the recommender\n",
    "\n",
    "most_popular_recommender = MostPopularRecommender()\n",
    "most_popular_recommender.fit(ml_ratings_df, None, ml_movies_df)\n",
    "recommendations = most_popular_recommender.recommend(pd.DataFrame([[1], [2], [6]], columns=['user_id']), ml_movies_df, 10)\n",
    "\n",
    "recommendations = pd.merge(recommendations, ml_movies_df, on='item_id', how='left')\n",
    "print(\"Recommendations\")\n",
    "display(HTML(recommendations.to_html()))\n",
    "\n",
    "most_popular_recommender = MostPopularRecommender()\n",
    "\n",
    "most_popular_results = [['MostPopularRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    most_popular_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df, max_evals=300, seed=6789))]\n",
    "\n",
    "most_popular_results = pd.DataFrame(\n",
    "    most_popular_results, \n",
    "    columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(most_popular_results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "endangered-designer",
   "metadata": {},
   "source": [
    "**Task 2.** Implement the HighestRatedRecommender (check the slides for class 1), evaluate it with leave-one-out procedure for implicit feedback, print HR@1, HR@3, HR@5, HR@10, NDCG@1, NDCG@3, NDCG@5, NDCG@10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "robust-agenda",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'HighestRatedRecommender' object has no attribute 'highest_ratings'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36m<cell line: 55>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     53\u001b[0m highest_rated_recommender \u001b[38;5;241m=\u001b[39m HighestRatedRecommender()\n\u001b[0;32m     54\u001b[0m highest_rated_recommender\u001b[38;5;241m.\u001b[39mfit(ml_ratings_df, \u001b[38;5;28;01mNone\u001b[39;00m, ml_movies_df)\n\u001b[1;32m---> 55\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m \u001b[43mhighest_rated_recommender\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecommend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m6\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43muser_id\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mml_movies_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(recommendations, ml_movies_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecommendations\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[1;32mIn [13]\u001b[0m, in \u001b[0;36mHighestRatedRecommender.recommend\u001b[1;34m(self, users_df, items_df, n_recommendations)\u001b[0m\n\u001b[0;32m     40\u001b[0m recommendations \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ix, user \u001b[38;5;129;01min\u001b[39;00m users_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Write your code here\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     user_recommendations \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m: [user[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m'\u001b[39m]],\n\u001b[0;32m     45\u001b[0m                                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mitem_id\u001b[39m\u001b[38;5;124m'\u001b[39m: [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhighest_rated_item],\n\u001b[1;32m---> 46\u001b[0m                                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mscore\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhighest_ratings\u001b[49m[:n_recommendations] \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m5\u001b[39m})\n\u001b[0;32m     47\u001b[0m     recommendations \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([recommendations, user_recommendations])\n\u001b[0;32m     49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m recommendations\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'HighestRatedRecommender' object has no attribute 'highest_ratings'"
     ]
    }
   ],
   "source": [
    "class HighestRatedRecommender(Recommender):\n",
    "    \"\"\"\n",
    "    Base recommender class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.highest_rated_item = None\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        # Write your code here\n",
    "        offer_ratings = interactions_df.loc[:, ['item_id', 'rating']].groupby(by='item_id').mean()\n",
    "        offer_counts = interactions_df.loc[:, ['item_id', 'rating']].groupby(by='item_id').count()\n",
    "        offer_ratings = offer_ratings.loc[offer_counts['rating'] >= 50]\n",
    "        offer_ratings = offer_ratings.sort_values('rating', ascending=False)\n",
    "        self.highest_rated_items = offer_ratings.index[:1]\n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        for ix, user in users_df.iterrows():\n",
    "            # Write your code here\n",
    "            user_recommendations = pd.DataFrame({'user_id': [user['user_id']],\n",
    "                                                 'item_id': [self.highest_rated_item],\n",
    "                                                 'score': self.highest_ratings[:n_recommendations] / 5})\n",
    "            recommendations = pd.concat([recommendations, user_recommendations])\n",
    "\n",
    "        return recommendations\n",
    "    \n",
    "# Quick test of the recommender\n",
    "\n",
    "highest_rated_recommender = HighestRatedRecommender()\n",
    "highest_rated_recommender.fit(ml_ratings_df, None, ml_movies_df)\n",
    "recommendations = highest_rated_recommender.recommend(pd.DataFrame([[1], [2], [6]], columns=['user_id']), ml_movies_df, 10)\n",
    "\n",
    "recommendations = pd.merge(recommendations, ml_movies_df, on='item_id')\n",
    "print(\"Recommendations\")\n",
    "display(HTML(recommendations.to_html()))\n",
    "\n",
    "highest_rated_recommender = HighestRatedRecommender()\n",
    "\n",
    "highest_rated_results = [['HighestRatedRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    highest_rated_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id', 'rating']], ml_movies_df, max_evals=300, seed=6789))]\n",
    "\n",
    "highest_rated_results = pd.DataFrame(\n",
    "    highest_rated_results, \n",
    "    columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(highest_rated_results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "valid-malaysia",
   "metadata": {},
   "source": [
    "**Task 3.** Implement the RandomRecommender (check the slides for class 1), evaluate it with leave-one-out procedure for implicit feedback, print HR@1, HR@3, HR@5, HR@10, NDCG@1, NDCG@3, NDCG@5, NDCG@10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "french-multiple",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>score</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>I'll Do Anything (1994)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>26631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Alice (Neco z Alenky) (1988)</td>\n",
       "      <td>Animation|Fantasy|Mystery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>63276</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Crows Zero (Kur√¥zu zero) (2007)</td>\n",
       "      <td>Action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2815</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Iron Eagle (1986)</td>\n",
       "      <td>Action|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>31553</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Double Dragon (1994)</td>\n",
       "      <td>Action|Adventure|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>46335</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Fast and the Furious: Tokyo Drift, The (Fast and the Furious 3, The) (2006)</td>\n",
       "      <td>Action|Crime|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>1107</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Loser (1991)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>42728</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Tristan &amp; Isolde (2006)</td>\n",
       "      <td>Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>4558</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Twins (1988)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>77866</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Robin Hood (2010)</td>\n",
       "      <td>Action|Adventure|Drama|Romance|War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2</td>\n",
       "      <td>66335</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Afro Samurai: Resurrection (2009)</td>\n",
       "      <td>Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2</td>\n",
       "      <td>91974</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Underworld: Awakening (2012)</td>\n",
       "      <td>Action|Fantasy|Horror|IMAX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2</td>\n",
       "      <td>3846</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Easy Money (1983)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2</td>\n",
       "      <td>4397</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cannonball Run II (1984)</td>\n",
       "      <td>Action|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2</td>\n",
       "      <td>2304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Love Is the Devil (1998)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2</td>\n",
       "      <td>5093</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Collateral Damage (2002)</td>\n",
       "      <td>Action|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2</td>\n",
       "      <td>85565</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Chalet Girl (2011)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2</td>\n",
       "      <td>85394</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cave of Forgotten Dreams (2010)</td>\n",
       "      <td>Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2</td>\n",
       "      <td>89087</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Colombiana (2011)</td>\n",
       "      <td>Action|Adventure|Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>1346</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cat People (1982)</td>\n",
       "      <td>Drama|Fantasy|Horror</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>6</td>\n",
       "      <td>108795</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Wonder Woman (2009)</td>\n",
       "      <td>Action|Adventure|Animation|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>6</td>\n",
       "      <td>4773</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Haiku Tunnel (2001)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6</td>\n",
       "      <td>5513</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Martin Lawrence Live: Runteldat (2002)</td>\n",
       "      <td>Comedy|Documentary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>6</td>\n",
       "      <td>8340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Escape from Alcatraz (1979)</td>\n",
       "      <td>Drama|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>6</td>\n",
       "      <td>7988</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Space Truckers (1996)</td>\n",
       "      <td>Comedy|Sci-Fi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6</td>\n",
       "      <td>6927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Human Stain, The (2003)</td>\n",
       "      <td>Drama|Romance|Thriller</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>6</td>\n",
       "      <td>95004</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Superman/Doomsday (2007)</td>\n",
       "      <td>Action|Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>6</td>\n",
       "      <td>5585</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Ernest Scared Stupid (1991)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>2088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Popeye (1980)</td>\n",
       "      <td>Adventure|Comedy|Musical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>6</td>\n",
       "      <td>1489</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Cats Don't Dance (1997)</td>\n",
       "      <td>Animation|Children|Musical</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Recommender</th>\n",
       "      <th>HR@1</th>\n",
       "      <th>HR@3</th>\n",
       "      <th>HR@5</th>\n",
       "      <th>HR@10</th>\n",
       "      <th>NDCG@1</th>\n",
       "      <th>NDCG@3</th>\n",
       "      <th>NDCG@5</th>\n",
       "      <th>NDCG@10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RandomRecommender</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.004828</td>\n",
       "      <td>0.00588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class RandomRecommender(Recommender):\n",
    "    \"\"\"\n",
    "    Base recommender class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, seed=0):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \n",
    "        :param int seed: Seed for the random number generator.\n",
    "        \"\"\"\n",
    "        self.seed = seed\n",
    "        self.rng = np.random.RandomState(seed=seed)\n",
    "        self.items = []\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        self.items = items_df['item_id'].unique().tolist()\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        # Write your code here\n",
    "        for ix, user in users_df.iterrows():\n",
    "            user_recommendations = pd.DataFrame({'user_id': user['user_id'],\n",
    "                                                 'item_id': self.rng.choice(self.items, n_recommendations, replace=False),\n",
    "                                                 'score': 1.0})\n",
    "\n",
    "            recommendations = pd.concat([recommendations, user_recommendations])\n",
    "            \n",
    "        recommendations = recommendations.reset_index(drop=True)\n",
    "\n",
    "        return recommendations\n",
    "    \n",
    "# Quick test of the recommender\n",
    "\n",
    "random_recommender = RandomRecommender(seed=6789)\n",
    "random_recommender.fit(ml_ratings_df, None, ml_movies_df)\n",
    "recommendations = random_recommender.recommend(pd.DataFrame([[1], [2], [6]], columns=['user_id']), ml_movies_df, 10)\n",
    "\n",
    "recommendations = recommendations.merge(ml_movies_df, on='item_id', how='left')\n",
    "print(\"Recommendations\")\n",
    "display(HTML(recommendations.to_html()))\n",
    "\n",
    "random_recommender = RandomRecommender(seed=seed)\n",
    "\n",
    "random_results = [['RandomRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    random_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id', 'rating']], ml_movies_df, max_evals=300, seed=seed))]\n",
    "\n",
    "random_results = pd.DataFrame(\n",
    "    random_results, \n",
    "    columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(HTML(random_results.to_html()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-chain",
   "metadata": {},
   "source": [
    "# Linear Regression Recommender\n",
    "\n",
    "For every movie we transform its genres into one-hot encoded features and we normalize them, for every user we count percentages for all genres how often do they appear among films watched by the user, we multiply both vectors (for the item and the user) to obtain explanaytory variables, and then we fit a linear regression model to those features and actual ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spanish-employee",
   "metadata": {},
   "source": [
    "**Task 4.** Implement the calculate_user_genres method for calculating a DataFrame with one row per user and columns corresponding to genres (e.g. 'user_action', 'user_drama') with values calculated as follows:\n",
    "\n",
    "- count the number of times a given user watched a given genre,\n",
    "- apply a natural logarithm to this value plus one,\n",
    "- normalize those values so that the sum of them over all columns within a row is equal to 1.\n",
    "\n",
    "Implement the calculate_item_genres method for replacing the 'genres' column with one column per genre (e.g. 'action', 'drama') with values calculated as follows:\n",
    "\n",
    "- place 1 in every column for which the genre appears in genres,\n",
    "- normalize those values so that the sum of them over all genre columns within a row is equal to 1.\n",
    "\n",
    "If item_features is None, then first find all genres and prepare a list of them. If item_features is not None, then create columns baed on this list. Return both the transformed DataFrame and the list of genres. Do not use MultiLabelBinarizer.\n",
    "\n",
    "Note that in this second method you have to preserve the remaining structure of the DataFrame.\n",
    "\n",
    "Evaluate the LinearRegressionRecommender with it using leave-one-out procedure for implicit feedback, print HR@1, HR@3, HR@5, HR@10, NDCG@1, NDCG@3, NDCG@5, NDCG@10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "olympic-runner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for tests\n",
    "interactions_df = pd.merge(ml_ratings_df, ml_movies_df, on='item_id')\n",
    "interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.replace(\"-\", \"_\", regex=False)\n",
    "interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.replace(\" \", \"_\", regex=False)\n",
    "interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.replace(\"(\", \"\", regex=False)\n",
    "interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.replace(\")\", \"\", regex=False)\n",
    "interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.lower()\n",
    "interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.split(\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "pressing-domain",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_user_genres(interactions_df):\n",
    "    users_df = interactions_df.copy()\n",
    "    users_df = users_df[['user_id', 'genres']]\n",
    "    users_df = users_df.explode('genres')\n",
    "    users_df['val'] = 1\n",
    "    users_df = users_df.pivot_table(index='user_id', columns='genres', values='val', aggfunc='count')\n",
    "    users_df = users_df / users_df.sum(axis=1).values.reshape(-1, 1)\n",
    "    users_df = users_df.rename_axis(None, axis=1).fillna(0)\n",
    "    users_df = users_df.add_prefix('user_')\n",
    "    return users_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "japanese-pound",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_action</th>\n",
       "      <th>user_adventure</th>\n",
       "      <th>user_animation</th>\n",
       "      <th>user_children</th>\n",
       "      <th>user_comedy</th>\n",
       "      <th>user_crime</th>\n",
       "      <th>user_documentary</th>\n",
       "      <th>user_drama</th>\n",
       "      <th>user_fantasy</th>\n",
       "      <th>user_film_noir</th>\n",
       "      <th>user_horror</th>\n",
       "      <th>user_imax</th>\n",
       "      <th>user_musical</th>\n",
       "      <th>user_mystery</th>\n",
       "      <th>user_no_genres_listed</th>\n",
       "      <th>user_romance</th>\n",
       "      <th>user_sci_fi</th>\n",
       "      <th>user_thriller</th>\n",
       "      <th>user_war</th>\n",
       "      <th>user_western</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.149254</td>\n",
       "      <td>0.119403</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.119403</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.044776</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.059701</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.014925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.062500</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.089286</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035714</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.017857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>0.048889</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.164444</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.297778</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.008889</td>\n",
       "      <td>0.004444</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.124444</td>\n",
       "      <td>0.031111</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>0.004444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>0.148936</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.127660</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212766</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>0.120172</td>\n",
       "      <td>0.055794</td>\n",
       "      <td>0.021459</td>\n",
       "      <td>0.064378</td>\n",
       "      <td>0.184549</td>\n",
       "      <td>0.077253</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.107296</td>\n",
       "      <td>0.055794</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051502</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>0.017167</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.042918</td>\n",
       "      <td>0.077253</td>\n",
       "      <td>0.098712</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>0.151899</td>\n",
       "      <td>0.063291</td>\n",
       "      <td>0.015823</td>\n",
       "      <td>0.015823</td>\n",
       "      <td>0.107595</td>\n",
       "      <td>0.069620</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.110759</td>\n",
       "      <td>0.034810</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.110759</td>\n",
       "      <td>0.031646</td>\n",
       "      <td>0.003165</td>\n",
       "      <td>0.034810</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.022152</td>\n",
       "      <td>0.085443</td>\n",
       "      <td>0.123418</td>\n",
       "      <td>0.009494</td>\n",
       "      <td>0.006329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>598 rows √ó 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_action  user_adventure  user_animation  user_children  \\\n",
       "user_id                                                               \n",
       "1           0.149254        0.119403        0.044776       0.074627   \n",
       "2           0.125000        0.000000        0.000000       0.000000   \n",
       "3           0.285714        0.000000        0.000000       0.000000   \n",
       "4           0.017857        0.017857        0.035714       0.053571   \n",
       "5           0.000000        0.000000        0.058824       0.058824   \n",
       "...              ...             ...             ...            ...   \n",
       "606         0.048889        0.040000        0.008889       0.022222   \n",
       "607         0.148936        0.063830        0.000000       0.021277   \n",
       "608         0.120172        0.055794        0.021459       0.064378   \n",
       "609         0.200000        0.400000        0.000000       0.200000   \n",
       "610         0.151899        0.063291        0.015823       0.015823   \n",
       "\n",
       "         user_comedy  user_crime  user_documentary  user_drama  user_fantasy  \\\n",
       "user_id                                                                        \n",
       "1           0.119403    0.089552          0.000000    0.059701      0.044776   \n",
       "2           0.000000    0.125000          0.000000    0.375000      0.000000   \n",
       "3           0.000000    0.000000          0.000000    0.000000      0.142857   \n",
       "4           0.196429    0.089286          0.000000    0.267857      0.035714   \n",
       "5           0.058824    0.058824          0.000000    0.176471      0.058824   \n",
       "...              ...         ...               ...         ...           ...   \n",
       "606         0.164444    0.066667          0.004444    0.297778      0.044444   \n",
       "607         0.127660    0.085106          0.000000    0.212766      0.021277   \n",
       "608         0.184549    0.077253          0.000000    0.107296      0.055794   \n",
       "609         0.000000    0.000000          0.000000    0.000000      0.000000   \n",
       "610         0.107595    0.069620          0.000000    0.110759      0.034810   \n",
       "\n",
       "         user_film_noir  user_horror  user_imax  user_musical  user_mystery  \\\n",
       "user_id                                                                       \n",
       "1              0.000000     0.000000   0.000000      0.014925      0.014925   \n",
       "2              0.000000     0.000000   0.000000      0.000000      0.000000   \n",
       "3              0.000000     0.142857   0.000000      0.000000      0.000000   \n",
       "4              0.017857     0.000000   0.017857      0.053571      0.000000   \n",
       "5              0.000000     0.000000   0.058824      0.058824      0.058824   \n",
       "...                 ...          ...        ...           ...           ...   \n",
       "606            0.004444     0.013333   0.008889      0.004444      0.022222   \n",
       "607            0.000000     0.063830   0.000000      0.021277      0.021277   \n",
       "608            0.000000     0.051502   0.008584      0.008584      0.017167   \n",
       "609            0.000000     0.000000   0.000000      0.000000      0.000000   \n",
       "610            0.003165     0.110759   0.031646      0.003165      0.034810   \n",
       "\n",
       "         user_no_genres_listed  user_romance  user_sci_fi  user_thriller  \\\n",
       "user_id                                                                    \n",
       "1                          0.0      0.074627     0.059701       0.089552   \n",
       "2                          0.0      0.062500     0.062500       0.187500   \n",
       "3                          0.0      0.000000     0.285714       0.142857   \n",
       "4                          0.0      0.125000     0.000000       0.035714   \n",
       "5                          0.0      0.176471     0.000000       0.058824   \n",
       "...                        ...           ...          ...            ...   \n",
       "606                        0.0      0.124444     0.031111       0.066667   \n",
       "607                        0.0      0.042553     0.085106       0.063830   \n",
       "608                        0.0      0.042918     0.077253       0.098712   \n",
       "609                        0.0      0.000000     0.200000       0.000000   \n",
       "610                        0.0      0.022152     0.085443       0.123418   \n",
       "\n",
       "         user_war  user_western  \n",
       "user_id                          \n",
       "1        0.029851      0.014925  \n",
       "2        0.000000      0.062500  \n",
       "3        0.000000      0.000000  \n",
       "4        0.017857      0.017857  \n",
       "5        0.058824      0.058824  \n",
       "...           ...           ...  \n",
       "606      0.022222      0.004444  \n",
       "607      0.021277      0.000000  \n",
       "608      0.008584      0.000000  \n",
       "609      0.000000      0.000000  \n",
       "610      0.009494      0.006329  \n",
       "\n",
       "[598 rows x 20 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Test the calculate_user_genres method\n",
    "display(calculate_user_genres(interactions_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "excited-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "def calculate_item_genres(item_genres, item_features=None):\n",
    "    item_genres = item_genres.copy()\n",
    "    if item_features is None:\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        item_genres = item_genres.join(\n",
    "            pd.DataFrame(mlb.fit_transform(item_genres.pop('genres')),\n",
    "                         columns=mlb.classes_,\n",
    "                         index=item_genres.index))\n",
    "\n",
    "        item_genres[mlb.classes_] = item_genres[mlb.classes_] \\\n",
    "            / item_genres[mlb.classes_].sum(axis=1).values.reshape(-1, 1)\n",
    "        \n",
    "        item_features = list(mlb.classes_)\n",
    "    else:\n",
    "        item_genres_pivot = item_genres[['item_id', 'genres']].explode('genres')\n",
    "        item_genres_pivot['val'] = 1\n",
    "        item_genres_pivot = item_genres_pivot.pivot_table(index='item_id', columns='genres', values='val')\n",
    "        item_genres_pivot = item_genres_pivot.rename_axis(None, axis=1).fillna(0)\n",
    "        item_genres_pivot = item_genres_pivot.reindex(item_features, axis=1).fillna(0).reset_index()\n",
    "        item_genres = item_genres.merge(item_genres_pivot, on='item_id')\n",
    "        \n",
    "        item_genres[item_features] = item_genres[item_features] \\\n",
    "            / item_genres[item_features].sum(axis=1).values.reshape(-1, 1)\n",
    "    return item_genres, item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "light-attitude",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MultiLabelBinarizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [22]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Test the calculate_item_genres method\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m item_genres, item_features \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_item_genres\u001b[49m\u001b[43m(\u001b[49m\u001b[43minteractions_df\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m display(item_genres)\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(item_features)\n",
      "Input \u001b[1;32mIn [21]\u001b[0m, in \u001b[0;36mcalculate_item_genres\u001b[1;34m(item_genres, item_features)\u001b[0m\n\u001b[0;32m      2\u001b[0m item_genres \u001b[38;5;241m=\u001b[39m item_genres\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m item_features \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m----> 4\u001b[0m     mlb \u001b[38;5;241m=\u001b[39m \u001b[43mMultiLabelBinarizer\u001b[49m()\n\u001b[0;32m      5\u001b[0m     item_genres \u001b[38;5;241m=\u001b[39m item_genres\u001b[38;5;241m.\u001b[39mjoin(\n\u001b[0;32m      6\u001b[0m         pd\u001b[38;5;241m.\u001b[39mDataFrame(mlb\u001b[38;5;241m.\u001b[39mfit_transform(item_genres\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenres\u001b[39m\u001b[38;5;124m'\u001b[39m)),\n\u001b[0;32m      7\u001b[0m                      columns\u001b[38;5;241m=\u001b[39mmlb\u001b[38;5;241m.\u001b[39mclasses_,\n\u001b[0;32m      8\u001b[0m                      index\u001b[38;5;241m=\u001b[39mitem_genres\u001b[38;5;241m.\u001b[39mindex))\n\u001b[0;32m     10\u001b[0m     item_genres[mlb\u001b[38;5;241m.\u001b[39mclasses_] \u001b[38;5;241m=\u001b[39m item_genres[mlb\u001b[38;5;241m.\u001b[39mclasses_] \\\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;241m/\u001b[39m item_genres[mlb\u001b[38;5;241m.\u001b[39mclasses_]\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'MultiLabelBinarizer' is not defined"
     ]
    }
   ],
   "source": [
    "# Test the calculate_item_genres method\n",
    "\n",
    "item_genres, item_features = calculate_item_genres(interactions_df)\n",
    "display(item_genres)\n",
    "print(item_features)\n",
    "\n",
    "item_genres, item_features = calculate_item_genres(interactions_df, ['comedy', 'crime', 'drama', 'horror', 'test_category'])\n",
    "display(item_genres)\n",
    "print(item_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sonic-horror",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class LinearRegressionRecommender(Recommender):\n",
    "    \"\"\"\n",
    "    Base recommender class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.model = None\n",
    "        self.users_dict = None\n",
    "        self.user_features = None\n",
    "        self.item_features = None\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Transform genres to a more code-friendly form\n",
    "        \n",
    "        interactions_df = pd.merge(interactions_df, items_df, on='item_id')\n",
    "        interactions_df = self._transform_genres(interactions_df)\n",
    "        \n",
    "        # Prepare user features\n",
    "\n",
    "        users_df = calculate_user_genres(interactions_df)\n",
    "        \n",
    "        self.users_dict = users_df.to_dict('index')\n",
    "        \n",
    "        self.user_features = users_df.columns.tolist()\n",
    "        \n",
    "        interactions_df = interactions_df.merge(users_df, on='user_id')\n",
    "                \n",
    "        # Prepare item features\n",
    "        \n",
    "        interactions_df, self.item_features = calculate_item_genres(interactions_df)\n",
    "\n",
    "        # Prepare input data and fit the model\n",
    "    \n",
    "        interactions_df[self.user_features] = interactions_df[self.user_features] \\\n",
    "            * interactions_df[self.user_features].values\n",
    "        \n",
    "        x = interactions_df.loc[:, self.user_features].values\n",
    "        y = interactions_df['rating'].values\n",
    "    \n",
    "        self.model = LinearRegression().fit(x, y)\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        # Transform the item to be scored into proper features\n",
    "        \n",
    "        items_df = items_df.copy()\n",
    "        items_df = self._transform_genres(items_df)\n",
    "        \n",
    "        items_df, _ = calculate_item_genres(items_df, self.item_features)\n",
    "\n",
    "        # Score the item\n",
    "    \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        for ix, user in users_df.iterrows():\n",
    "            if user['user_id'] in self.users_dict:\n",
    "                user_df = pd.DataFrame.from_dict({user['user_id']: self.users_dict[user['user_id']]}, orient='index')\n",
    "            else:\n",
    "                user_df = pd.DataFrame.from_dict(\n",
    "                    {user['user_id']: [1 / len(self.user_features)]*len(self.user_features)}, orient='index')\n",
    "#             display(user_df)\n",
    "#             display(items_df)\n",
    "            input_df = items_df.copy()\n",
    "            input_df[self.item_features] = items_df[self.item_features] * user_df.values\n",
    "#             display(input_df)\n",
    "            scores = self.model.predict(input_df.loc[:, self.item_features].values)\n",
    "    \n",
    "            chosen_pos = np.argsort(-scores)[:n_recommendations]\n",
    "        \n",
    "            user_recommendations = []\n",
    "            for item_pos in chosen_pos:\n",
    "                user_recommendations.append(\n",
    "                    {\n",
    "                        'user_id': user['user_id'],\n",
    "                        'item_id': input_df.iloc[item_pos]['item_id'],\n",
    "                        'score': scores[item_pos]\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "            user_recommendations = pd.DataFrame(user_recommendations)\n",
    "\n",
    "            recommendations = pd.concat([recommendations, user_recommendations])\n",
    "\n",
    "        return recommendations\n",
    "    \n",
    "    def _transform_genres(self, df):\n",
    "        \"\"\"\n",
    "        Transforms a string with genres into a list of cleaned genre names.\n",
    "        \n",
    "        :param pd.DataFrame df: A DataFrame with 'genres' column.\n",
    "        \"\"\"\n",
    "        df.loc[:, 'genres'] = df['genres'].str.replace(\"-\", \"_\", regex=False)\n",
    "        df.loc[:, 'genres'] = df['genres'].str.replace(\" \", \"_\", regex=False)\n",
    "        df.loc[:, 'genres'] = df['genres'].str.replace(\"(\", \"\", regex=False)\n",
    "        df.loc[:, 'genres'] = df['genres'].str.replace(\")\", \"\", regex=False)\n",
    "        df.loc[:, 'genres'] = df['genres'].str.lower()\n",
    "        df.loc[:, 'genres'] = df['genres'].str.split(\"|\")\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colored-favorite",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Quick test of the recommender\n",
    "\n",
    "lr_recommender = LinearRegressionRecommender()\n",
    "lr_recommender.fit(ml_ratings_df, None, ml_movies_df)\n",
    "recommendations = lr_recommender.recommend(pd.DataFrame([[1], [2]], columns=['user_id']), ml_movies_df, 10)\n",
    "\n",
    "recommendations = pd.merge(recommendations, ml_movies_df, on='item_id', how='left')\n",
    "display(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "usual-archives",
   "metadata": {},
   "source": [
    "### Train-test split test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bound-offer",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_recommender = LinearRegressionRecommender()\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "results = [['LinearRegressionRecommender'] + list(evaluate_train_test_split_explicit(\n",
    "    lr_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id', 'rating']], ml_movies_df, seed=seed))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'RMSE', 'MRE', 'TRE'])\n",
    "\n",
    "display(results)\n",
    "\n",
    "print('Total evaluation time: {}'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-warehouse",
   "metadata": {},
   "source": [
    "### Leave-one-out test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "national-sight",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_recommender = LinearRegressionRecommender()\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "results = [['LinearRegressionRecommender'] + list(evaluate_leave_one_out_explicit(\n",
    "    lr_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id', 'rating']], ml_movies_df, seed=seed))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'RMSE', 'MRE', 'TRE'])\n",
    "\n",
    "display(results)\n",
    "\n",
    "print('Total evaluation time: {}'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "static-mozambique",
   "metadata": {},
   "source": [
    "# TF-IDF Recommender\n",
    "TF-IDF stands for term frequency‚Äìinverse document frequency. Typically Tf-IDF method is used to assign keywords (words describing the gist of a document) to documents in a corpus of documents.\n",
    "\n",
    "In our case we will treat users as documents and genres as words.\n",
    "\n",
    "Term-frequency is given by the following formula:\n",
    "<center>\n",
    "$$\n",
    "    \\text{tf}(g, u) = f_{g, u}\n",
    "$$\n",
    "</center>\n",
    "where $f_{g, i}$ is the number of times genre $g$ appear for movies watched by user $u$.\n",
    "\n",
    "Inverse document frequency is defined as follows:\n",
    "<center>\n",
    "$$\n",
    "    \\text{idf}(g) = \\log \\frac{N}{n_g}\n",
    "$$\n",
    "</center>\n",
    "where $N$ is the number of users and $n_g$ is the number of users with $g$ in their genres list.\n",
    "\n",
    "Finally, tf-idf is defined as follows:\n",
    "<center>\n",
    "$$\n",
    "    \\text{tfidf}(g, u) = \\text{tf}(g, u) \\cdot \\text{idf}(g)\n",
    "$$\n",
    "</center>\n",
    "\n",
    "In our case we will measure how often a given genre appears for movies watched by a given user vs how often it appears for all users. To obtain a movie score we will take the average of its genres' scores for this user."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-cursor",
   "metadata": {},
   "source": [
    "**Task 5.** Implement the following method for calculating a TF-IDF scores in a form of a dict (use defaultdict):\n",
    "\n",
    "`{(1, 'action'): 0.45306430692185395, (1, 'adventure'): 0.39370003643934415, (1, 'animation'): 0.20886242957049514, ...}`\n",
    "\n",
    "without using TfidfVectorizer (you can use loops).\n",
    "\n",
    "Evaluate the TFIDFRecommender with it using leave-one-out procedure for implicit feedback, print HR@1, HR@3, HR@5, HR@10, NDCG@1, NDCG@3, NDCG@5, NDCG@10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frank-active",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_tf_idf_scores():\n",
    "    # Write your code here\n",
    "    \n",
    "    return tfidf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "retained-traffic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the method\n",
    "interactions_df = pd.merge(ml_ratings_df, ml_movies_df, on='item_id')\n",
    "interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.replace(\"-\", \"_\", regex=False)\n",
    "interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.replace(\" \", \"_\", regex=False)\n",
    "interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.lower()\n",
    "        \n",
    "tfidf_scores = calculate_tf_idf_scores(interactions_df)\n",
    "print(tfidf_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infrared-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFIDFRecommender(Recommender):\n",
    "    \"\"\"\n",
    "    Recommender based on the TF-IDF method.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.tfidf_scores = None\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.tfidf_scores = defaultdict(lambda: 0.0)\n",
    "\n",
    "        # Prepare the corpus for tfidf calculation\n",
    "        \n",
    "        interactions_df = pd.merge(interactions_df, items_df, on='item_id')\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.replace(\"-\", \"_\", regex=False)\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.replace(\" \", \"_\", regex=False)\n",
    "        interactions_df.loc[:, 'genres'] = interactions_df['genres'].str.lower()\n",
    "                \n",
    "        self.tfidf_scores = calculate_tf_idf_scores(interactions_df)\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        recommendations = pd.DataFrame(columns=['user_id', 'item_id', 'score'])\n",
    "        \n",
    "        # Transform genres to a unified form used by the vectorizer\n",
    "        \n",
    "        items_df = items_df.copy()\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.replace(\"-\", \"_\", regex=False)\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.replace(\" \", \"_\", regex=False)\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.lower()\n",
    "        items_df.loc[:, 'genres'] = items_df['genres'].str.split(\"|\")\n",
    "                \n",
    "        # Score items    \n",
    "        \n",
    "        for uix, user in users_df.iterrows():\n",
    "            items = []\n",
    "            for iix, item in items_df.iterrows():\n",
    "                score = 0.0\n",
    "                for genre in item['genres']:\n",
    "                    score += self.tfidf_scores[(user['user_id'], genre)]\n",
    "                score /= len(item['genres'])\n",
    "                items.append((item['item_id'], score))\n",
    "                \n",
    "            items = sorted(items, key=lambda x: x[1], reverse=True)\n",
    "            user_recommendations = pd.DataFrame({'user_id': user['user_id'],\n",
    "                                                 'item_id': [item[0] for item in items][:n_recommendations],\n",
    "                                                 'score': [item[1] for item in items][:n_recommendations]})\n",
    "\n",
    "            recommendations = pd.concat([recommendations, user_recommendations])\n",
    "\n",
    "        return recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sorted-alcohol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print movies watched by user 1, 2\n",
    "\n",
    "active_user_movies = ml_df.loc[(ml_df['user_id'] == 1) | (ml_df['user_id'] == 2)]\n",
    "print(\"Active users history\")\n",
    "display(active_user_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriented-service",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick test of the recommender\n",
    "\n",
    "tfidf_recommender = TFIDFRecommender()\n",
    "tfidf_recommender.fit(ml_ratings_df, None, ml_movies_df)\n",
    "recommendations = tfidf_recommender.recommend(pd.DataFrame([[1], [2]], columns=['user_id']), ml_movies_df, 10)\n",
    "\n",
    "recommendations = pd.merge(recommendations, ml_movies_df, on='item_id', how='left')\n",
    "print(\"Recommendations\")\n",
    "display(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sealed-liberty",
   "metadata": {},
   "source": [
    "### Train-test split test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identified-destination",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_recommender = TFIDFRecommender()\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "results = [['TFIDFRecommender'] + list(evaluate_train_test_split_implicit(\n",
    "    tfidf_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(results)\n",
    "\n",
    "print('Total evaluation time: {}'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-beast",
   "metadata": {},
   "source": [
    "### Leave-one-out test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qualified-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_recommender = TFIDFRecommender()\n",
    "\n",
    "t0 = time.time()\n",
    "\n",
    "results = [['TFIDFRecommender'] + list(evaluate_leave_one_out_implicit(\n",
    "    tfidf_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id']], ml_movies_df, max_evals=300, seed=6789))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'HR@1', 'HR@3', 'HR@5', 'HR@10', 'NDCG@1', 'NDCG@3', 'NDCG@5', 'NDCG@10'])\n",
    "\n",
    "display(results)\n",
    "\n",
    "print('Total evaluation time: {}'.format(time.time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "visible-burlington",
   "metadata": {},
   "source": [
    "**Task 6\\*.** Implement an SVRRecommender by replacing the LinearRegression model with the SVR model (`from sklearn.svm import SVR`).\n",
    "\n",
    "Tune the C and epsilon params of the SVR model to obtain as good results as you can. \n",
    "\n",
    "To do tuning properly:\n",
    "\n",
    "- divide the set into training, validation and test sets (randomly divide the dataset in proportions 60%-20%-20%),\n",
    "- train the model with different sets of tunable parameters on the training set, \n",
    "- choose the best tunable params based on results on the validation set, \n",
    "- provide the final evaluation metrics on the test set for the best model obtained during tuning.\n",
    "\n",
    "Recommended method of tuning: use hyperopt. Install the package using the following command: `pip install hyperopt`\n",
    "    \n",
    "Print the RMSE, MAPE and TRE on the test set. Use seed 6789."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-gregory",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "class SVRRecommender(Recommender):\n",
    "    \"\"\"\n",
    "    SVR recommender class.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, kernel='rbf', C=1.0, epsilon=0.1):\n",
    "        \"\"\"\n",
    "        Initialize base recommender params and variables.\n",
    "        \"\"\"\n",
    "        self.model = None\n",
    "        self.kernel = kernel\n",
    "        self.C = C\n",
    "        self.epsilon = epsilon\n",
    "    \n",
    "    def fit(self, interactions_df, users_df, items_df):\n",
    "        \"\"\"\n",
    "        Training of the recommender.\n",
    "        \n",
    "        :param pd.DataFrame interactions_df: DataFrame with recorded interactions between users and items \n",
    "            defined by user_id, item_id and features of the interaction.\n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features defined by user_id and the user feature columns.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features defined by item_id and the item feature columns.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Write your code here\n",
    "    \n",
    "    def recommend(self, users_df, items_df, n_recommendations=1):\n",
    "        \"\"\"\n",
    "        Serving of recommendations. Scores items in items_df for each user in users_df and returns \n",
    "        top n_recommendations for each user.\n",
    "        \n",
    "        :param pd.DataFrame users_df: DataFrame with users and their features for which recommendations should be generated.\n",
    "        :param pd.DataFrame items_df: DataFrame with items and their features which should be scored.\n",
    "        :param int n_recommendations: Number of recommendations to be returned for each user.\n",
    "        :return: DataFrame with user_id, item_id and score as columns returning n_recommendations top recommendations \n",
    "            for each user.\n",
    "        :rtype: pd.DataFrame\n",
    "        \"\"\"\n",
    "        \n",
    "        # Write your code here\n",
    "\n",
    "        return recommendations\n",
    "    \n",
    "    \n",
    "# Quick test of the recommender\n",
    "\n",
    "svr_recommender = SVRRecommender()\n",
    "svr_recommender.fit(ml_ratings_df, None, ml_movies_df)\n",
    "recommendations = svr_recommender.recommend(pd.DataFrame([[1], [2], [6]], columns=['user_id']), ml_movies_df, 10)\n",
    "\n",
    "recommendations = pd.merge(recommendations, ml_movies_df, on='item_id', how='left')\n",
    "print(\"Recommendations\")\n",
    "display(recommendations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-guest",
   "metadata": {},
   "source": [
    "### Manually test different param configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "second-teach",
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_recommender = SVRRecommender(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "\n",
    "results = [['SVRRecommender'] + list(evaluate_train_test_split_explicit(\n",
    "    svr_recommender, ml_ratings_df.loc[:, ['user_id', 'item_id', 'rating']], ml_movies_df, seed=seed))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'RMSE', 'MRE', 'TRE'])\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thousand-julian",
   "metadata": {},
   "source": [
    "### Tune the SVRRecommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ambient-brother",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp, fmin, tpe, Trials\n",
    "\n",
    "# Split into train_validation and test sets\n",
    "\n",
    "shuffle = np.arange(len(ml_ratings_df))\n",
    "rng.shuffle(shuffle)\n",
    "shuffle = list(shuffle)\n",
    "\n",
    "train_test_split = 0.8\n",
    "split_index = int(len(ml_ratings_df) * train_test_split)\n",
    "\n",
    "train_validation = ml_ratings_df.iloc[shuffle[:split_index]].loc[:, ['user_id', 'item_id', 'rating']]\n",
    "test = ml_ratings_df.iloc[shuffle[split_index:]].loc[:, ['user_id', 'item_id', 'rating']]\n",
    "\n",
    "# Tune\n",
    "\n",
    "def loss(tuned_params):\n",
    "    svr_recommender = SVRRecommender(kernel='rbf', C=tuned_params['C'], epsilon=tuned_params['epsilon'])\n",
    "    rmse, mre, tre = evaluate_train_test_split_explicit(\n",
    "        svr_recommender, train_validation, ml_movies_df, seed=seed)\n",
    "    return rmse\n",
    "\n",
    "########################################################################\n",
    "# Write your code here \n",
    "# Read the code above and below and make sure you understand it\n",
    "# Minimize the above loss function using hyperopt\n",
    "# Save your best params under best_param_set\n",
    "########################################################################\n",
    "\n",
    "# Best params\n",
    "\n",
    "print(\"C = {}\".format(best_param_set['C']))\n",
    "print(\"epsilon = {}\".format(best_param_set['epsilon']))\n",
    "    \n",
    "# Test\n",
    "\n",
    "svr_recommender = SVRRecommender(C=best_param_set['C'], epsilon=best_param_set['epsilon'])\n",
    "\n",
    "results = [['SVRRecommender'] + list(evaluate_train_test_split_explicit(\n",
    "    svr_recommender, {'train': train_validation, 'test': test}, ml_movies_df, seed=seed))]\n",
    "\n",
    "results = pd.DataFrame(results, \n",
    "                       columns=['Recommender', 'RMSE', 'MRE', 'TRE'])\n",
    "\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "commercial-gathering",
   "metadata": {},
   "source": [
    "**Task 7.** Gather the results for LinearRegressionRecommender, SVRRecommender, TFIDFRecommender, MostPopularRecommender, HighestRatedRecommender, RandomRecommender from the evaluate_train_test_split_implicit method and print them as a single DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intermediate-captain",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your code here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
